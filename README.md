
# âœ… Fish-Speech 1.5 Inference (Windows-Friendly, Python-Only)

This repository contains **fully working Python scripts** for running **Fish-Speech 1.5 voice cloning** without needing the long and error-prone command-line process shown in the official repo.

The official Fish-Speech inference workflow requires multiple terminal commands, manual token extraction, and often fails on Windows due to:

- CUDA / Triton / bf16 incompatibility (especially GPUs like GTX 1650)
- Folder path issues (`config.json` not found, tokenizer not found)
- dtype and device mismatches (`cpu vs cuda`, `int64 vs int32`)
- VQGAN prompt extraction not documented properly
- Errors when using Windows paths with spaces

âœ… This repo fixes all of that by converting the entire process into **simple Python scripts** you can just run.

---

## ğŸš€ What this repo does

| Feature | Official Repo | This Repo |
|---------|---------------|-----------|
| Needs terminal commands | âœ… Yes | âŒ No |
| Requires manual prompt extraction | âœ… Yes | âŒ Auto-generated `fake.npy` |
| Crashes on Windows paths | âœ… Common | âŒ Fixed |
| Fails on GTX 1650 (no bfloat16 / Triton) | âœ… Yes | âŒ Disabled Triton + fp16 only |
| One-shot text â†’ voice cloning | âŒ Not provided | âœ… Yes |
| Saves multiple outputs (`output1.wav`, `output2.wav`, â€¦) | âŒ No | âœ… Yes |

---

## ğŸ“‚ Folder Structure

```
fish-speech1.5-inference/
â”‚â”€â”€ fish_inf2.py            # End-to-end cloning (WAV â†’ fake.npy â†’ generated speech)
â”‚â”€â”€ fish_inference.py       # Uses pre-existing fake.npy for fast text cloning
â”‚â”€â”€ extract_prompt.py       # (optional) WAV â†’ fake.npy only
â”‚â”€â”€ clone_and_speak.py      # alternative chaining script
â”‚â”€â”€ input/
â”‚   â””â”€â”€ ref.wav             # Your reference voice (3â€“10 sec clean speech)
â”‚â”€â”€ output/
â”‚   â”œâ”€â”€ output1.wav
â”‚   â”œâ”€â”€ output2.wav
â”‚   â””â”€â”€ fake.npy
â”‚â”€â”€ checkpoints/
â”‚   â””â”€â”€ fish-speech-1.5/    # model files (NOT included in repo)
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚â”€â”€ .gitignore
```

---

## ğŸ”§ Installation

1ï¸âƒ£ Clone the repo  
```bash
git clone https://github.com/yourname/fish-speech1.5-inference.git
cd fish-speech1.5-inference
```

2ï¸âƒ£ Create & activate virtual environment  
```bash
python -m venv venv
venv\Scripts\activate   # (Windows)
```

3ï¸âƒ£ Install dependencies  
```bash
pip install -r requirements.txt
```

4ï¸âƒ£ Download Fish-Speech 1.5 checkpoints manually and place under:

```
checkpoints/fish-speech-1.5/
    config.json
    model files...
    firefly-gan-vq-fsq-8x1024-21hz-generator.pth
```

ğŸ›‘ (They are **NOT** included here due to size + licensing.)

---

## ğŸ¤ How to Run Inference

### âœ… 1. Full automatic (WAV â†’ fake.npy â†’ speech outputs)

Place your reference voice at:

```
input/ref.wav
```

Then run:

```bash
python fish_inf2.py
```

You will get:

```
output/output1.wav
output/output2.wav
...
```

### âœ… 2. If you already have `fake.npy`

```bash
python fish_inference.py
```

### âœ… 3. Extract speaker prompt only (optional)

```bash
python extract_prompt.py
```

It will generate:

```
output/fake.npy
```

---

## âš™ï¸ Key Fixes Made vs. Official Repo

| Problem in Official Code | Fix in This Repo |
|--------------------------|------------------|
| Model expects folder, not config path | âœ… `load_model(ckpt_dir_folder)` fixed |
| VQGAN encode missing `audio_lengths` arg | âœ… Added correctly |
| Prompt tokens had wrong dtype (`int64`) | âœ… Converted to `int32` before saving |
| "device mismatch: cpu vs cuda" errors | âœ… Fixed by keeping prompt on same device |
| Triton compile crash on GTX GPUs | âœ… Disabled `compile=True`, used fp16 |
| Windows path with spaces breaks Torch | âœ… Used `raw strings r""` everywhere |
| Output overwrote same file | âœ… Now auto-names `output1.wav`, `output2.wav` |

---

## ğŸ§  Why this repo exists

The Fish-Speech team only provides CLI-based inference scripts that **break on Windows**, require CLI knowledge, and donâ€™t support automated multi-output generation.  
So this repo:

âœ… Converts all inference steps into clean Python scripts  
âœ… Works on Windows + low-VRAM GPUs (GTX 1650, 4â€“6GB)  
âœ… Removes need to run 5 different commands manually  
âœ… Lets you use **your own WAV** and get cloned speech in 1 step  

---

## ğŸ“œ Credits

- Original model: **Fish-Speech** (MIT License)
- Scripts rewritten + fixed by **Shreyas Patil**

---

## â­ If this repo helped you

Please star the repo and share it â€” the official repo offers no beginner-friendly inference for Windows users.
